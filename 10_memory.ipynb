{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06a1c63e",
   "metadata": {},
   "source": [
    "A maioria das aplicações de Modelos de LLM possui uma interface conversacional. Um componente essencial de uma conversa é a capacidade de se referir a informações introduzidas anteriormente na conversa. No mínimo, um sistema conversacional deve ser capaz de acessar diretamente alguma janela de mensagens passadas. Um sistema mais complexo precisará ter um modelo de mundo que está constantemente atualizando, o que lhe permite fazer coisas como manter informações sobre entidades e suas relações.\n",
    "\n",
    "Chamamos essa capacidade de armazenar informações sobre interações passadas de \"Memory\", ou memória. LangChain oferece muitas utilidades para adicionar memória a um sistema. Essas utilidades podem ser usadas por si só ou incorporadas de maneira integrada em uma chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a48c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "memory = InMemoryChatMessageHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d94880",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.add_user_message('Olá, modelo!')\n",
    "memory.add_ai_message('Olá, user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63cebe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Olá, modelo!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Olá, user', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd291f1d",
   "metadata": {},
   "source": [
    "## Criando uma conversa com memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c480bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um tutor de programação chamado Asimo. Responda as perguntas de forma didática.\"),\n",
    "    (\"placeholder\", \"{memoria}\"),\n",
    "    (\"human\", \"{pergunta}\"),\n",
    "])\n",
    "chain = prompt | ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cdf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain_com_memoria = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key='pergunta',\n",
    "    history_messages_key='memoria'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d71f620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá, Adriano! Como posso te ajudar hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 40, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ae30bcb9-e748-4071-8e45-c5014fcef6d9-0', usage_metadata={'input_tokens': 40, 'output_tokens': 15, 'total_tokens': 55, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable': {'session_id': 'usuaria_a'}}\n",
    "resposta = chain_com_memoria.invoke({'pergunta': 'O meu nome é Adriano'}, config=config)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99691be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seu nome é Adriano. Como posso te ajudar hoje, Adriano?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 68, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4b120450-d4f3-43f7-8724-4568341fb977-0', usage_metadata={'input_tokens': 68, 'output_tokens': 19, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = chain_com_memoria.invoke({'pergunta': 'Qual é o meu nome?'}, config=config)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e8fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Desculpe, mas não tenho acesso ao seu nome. Como posso te chamar? Como posso te ajudar hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 40, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dcd34e3b-1a22-47f5-a5a4-7802ee53175f-0', usage_metadata={'input_tokens': 40, 'output_tokens': 29, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable': {'session_id': 'usuaria_b'}}\n",
    "resposta = chain_com_memoria.invoke({'pergunta': 'Qual é o meu nome?'}, config=config)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10427d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadea18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
