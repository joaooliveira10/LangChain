# LangChain Project ğŸ”—

Uma poderosa biblioteca para construÃ§Ã£o de aplicaÃ§Ãµes baseadas em LLMs (Large Language Models), permitindo criar aplicaÃ§Ãµes de IA avanÃ§adas com processamento de linguagem natural.

## ğŸ“‹ Tabela de ConteÃºdos

- [LangChain Project ğŸ”—](#langchain-project-)
  - [ğŸ“‹ Tabela de ConteÃºdos](#-tabela-de-conteÃºdos)
  - [ğŸ” Sobre](#-sobre)
  - [âœ¨ Funcionalidades](#-funcionalidades)
  - [ğŸ“‹ PrÃ©-requisitos](#-prÃ©-requisitos)
  - [ğŸš€ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
  - [ğŸ® Como Usar](#-como-usar)
    - [InicializaÃ§Ã£o BÃ¡sica](#inicializaÃ§Ã£o-bÃ¡sica)
  - [ğŸ“ Exemplos](#-exemplos)
    - [Exemplo 1: Chatbot com MemÃ³ria](#exemplo-1-chatbot-com-memÃ³ria)
    - [Exemplo 2: Consulta a Documentos ğŸ“š](#exemplo-2-consulta-a-documentos-)
  - [âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada](#ï¸-configuraÃ§Ã£o-avanÃ§ada)
    - [PersonalizaÃ§Ã£o de Modelos](#personalizaÃ§Ã£o-de-modelos)

## ğŸ” Sobre

LangChain Ã© um framework que facilita o desenvolvimento de aplicaÃ§Ãµes utilizando modelos de linguagem. Ele permite combinar LLMs com outras fontes de computaÃ§Ã£o e conhecimento, criando aplicaÃ§Ãµes mais poderosas e contextuais.

## âœ¨ Funcionalidades

- **Chains**: Combine componentes em sequÃªncias para tarefas complexas
- **Prompts**: Gerenciamento e otimizaÃ§Ã£o de prompts para LLMs
- **Memory**: PersistÃªncia de estado entre chamadas de chain/agent
- **Agents**: Permita que LLMs decidam quais aÃ§Ãµes tomar
- **IntegraÃ§Ã£o com Dados**: Conecte seus LLMs a outras fontes de dados
- **Callbacks**: Hooks que permitem monitorar e depurar a execuÃ§Ã£o

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8.1 ou superior
- Pip (gerenciador de pacotes)
- Acesso a chaves de API para LLMs (OpenAI, Anthropic, etc.)

## ğŸš€ InstalaÃ§Ã£o

1. Clone este repositÃ³rio:

```bash
git clone https://github.com/joaooliveira10/LangChain.git
cd LangChain
```

2. Crie e ative um ambiente virtual (recomendado):

```bash
python -m venv venv
# No Windows
venv\Scripts\activate
# No macOS/Linux
source venv/bin/activate
```

3. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

4. Configure suas variÃ¡veis de ambiente:

```bash
# No Windows
set OPENAI_API_KEY=sua_chave_aqui
# No macOS/Linux
export OPENAI_API_KEY=sua_chave_aqui
```

## ğŸ® Como Usar

### InicializaÃ§Ã£o BÃ¡sica

```python
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# Inicialize o LLM
llm = OpenAI(temperature=0.7)

# Crie um template de prompt
prompt = PromptTemplate(
    input_variables=["produto"],
    template="O que vocÃª sabe sobre {produto}?",
)

# Crie uma chain
chain = LLMChain(llm=llm, prompt=prompt)

# Execute a chain
resposta = chain.run("LangChain")
print(resposta)
```

## ğŸ“ Exemplos

### Exemplo 1: Chatbot com MemÃ³ria

```python
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

conversation = ConversationChain(
    llm=llm,
    memory=ConversationBufferMemory()
)

response = conversation.predict(input="OlÃ¡! Como vocÃª estÃ¡?")
print(response)
```

### Exemplo 2: Consulta a Documentos ğŸ“š

```python
from langchain.document_loaders import TextLoader
from langchain.indexes import VectorstoreIndexCreator

loader = TextLoader("./meudocumento.txt")
index = VectorstoreIndexCreator().from_loaders([loader])

query = "Qual o principal tema deste documento?"
response = index.query(query)
```

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### PersonalizaÃ§Ã£o de Modelos

Para configurar diferentes modelos e parÃ¢metros, edite o arquivo `config.yml`:

```yaml
model:
  provider: openai
  name: gpt-3.5-turbo
  temperature: 0.7
  max_tokens: 500

memory:
  type: buffer
  k: 5
```
