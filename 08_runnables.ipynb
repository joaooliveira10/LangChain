{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos dos Runnables de LCEL\n",
    "\n",
    "A interface padrão de LCEL inclui os seguintes métodos:\n",
    "\n",
    "- **stream:** transmitir de volta fragmentos da resposta\n",
    "- **invoke:** chamar a cadeia com um input\n",
    "- **batch:** chamar a cadeia com uma lista de inputs\n",
    "\n",
    "Esses também possuem métodos assíncronos correspondentes que devem ser usados com a sintaxe `asyncio await` para concorrência:\n",
    "\n",
    "- **astream:** transmitir de volta fragmentos da resposta de forma assíncrona\n",
    "- **ainvoke:** chamar a cadeia com um input de forma assíncrona\n",
    "- **abatch:** chamar a cadeia com uma lista de inputs de forma assíncrona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie uma frase sobre o assunto: {assunto}\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "O invoke é o método básico para inserir uma input na cadeia e receber uma resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Os cachorrinhos são companheiros leais e amorosos que iluminam nossos dias com sua alegria e carinho.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 20, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c3971a54-cfee-4545-8765-03fbe1f5bfe0-0', usage_metadata={'input_tokens': 20, 'output_tokens': 31, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'assunto': 'cachorrinhos'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele pode ser rodado como uma simples string quando existe apenas uma input no prompt, mas a forma mais recomendada é informando especificamente o nome da input através de um dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cachorrinhos são a prova de que o amor incondicional pode vir em um pacote peludo e cheio de lambidas.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 20, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-277281c3-fc57-41d9-bfe7-06a215d72a9b-0', usage_metadata={'input_tokens': 20, 'output_tokens': 31, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('cachorrinhos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream\n",
    "\n",
    "Para recebermos uma saída conforme ela é gerada pelo modelo utilizamos o stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cachorrinhos são como pequenos raios de sol que iluminam nossos dias com amor e alegria."
     ]
    }
   ],
   "source": [
    "for stream in chain.stream('cachorrinhos'):\n",
    "    print(stream.content, end='') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n",
    "Para fazermos múltimpas requisições em paralelo utilizamos o batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Cachorrinhos são como pequenos raios de sol que iluminam nossas vidas com amor e alegria.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 20, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e8992de0-cba7-42ae-9cc0-6a1748123f31-0', usage_metadata={'input_tokens': 20, 'output_tokens': 30, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='\"Os gatinhos encantam com seus olhares curiosos e seus ronrons carinhosos, trazendo alegria e conforto para nossas vidas.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 19, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fc4c07c1-8fd6-4ea8-982a-086354422387-0', usage_metadata={'input_tokens': 19, 'output_tokens': 41, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='Os cavalinhos de madeira são brinquedos clássicos que encantam gerações de crianças.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 19, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-79d20b98-5422-4357-a72e-5ae1d546fb08-0', usage_metadata={'input_tokens': 19, 'output_tokens': 28, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinhos'}, {'assunto': 'cavalinhos'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Cachorrinhos são como pequenos anjos de quatro patas que trazem alegria e amor para nossas vidas.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 20, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e8c01b27-c31a-424a-9ce3-be62c11d8b0c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 32, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='\"Os gatinhos são como pequenos feitiços que encantam nossos corações com suas travessuras e carinhos.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 19, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3141c58c-ec07-4c9b-8b08-072f69796fa5-0', usage_metadata={'input_tokens': 19, 'output_tokens': 31, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='Os cavalinhos de carrossel sempre trazem alegria e nostalgia, nos transportando para um mundo de fantasia e diversão.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 19, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a916e61b-fda0-48b8-9404-39e2d9477c4c-0', usage_metadata={'input_tokens': 19, 'output_tokens': 32, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinhos'}, {'assunto': 'cavalinhos'}], config={'max_concurrency': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnables especiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rodando em paralelo\n",
    "```\n",
    "     Input      \n",
    "      / \\       \n",
    "     /   \\      \n",
    " Branch1 Branch2\n",
    "     \\   /      \n",
    "      \\ /       \n",
    "      Combine   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie um nome para o seguinte produto: {produto}\")\n",
    "\n",
    "chain_nome = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Descreva o cliente potencial para o seguinte produto: {produto}\")\n",
    "\n",
    "chain_clientes = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Dado o produto com o seguinte nome e seguinte\n",
    "público potencial, desenvolva um anúncio para o produto.\n",
    "                                          \n",
    "Nome do produto: {nome_produto}\n",
    "Público: {publico}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_produto': 'SuperCopo Invencível',\n",
       " 'publico': 'O cliente potencial para um copo inquebrável pode ser alguém que tem crianças em casa e está preocupado com a segurança delas, pois evita acidentes com vidro quebrado. Além disso, pessoas que gostam de praticar esportes ao ar livre, como camping, trilhas e atividades radicais, podem se interessar por um copo inquebrável por sua durabilidade e resistência. Outro público-alvo pode ser pessoas que são desastradas e costumam derrubar objetos com frequência, pois um copo inquebrável seria uma opção mais prática e econômica a longo prazo.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel = RunnableParallel({'nome_produto': chain_nome, 'publico': chain_clientes})\n",
    "parallel.invoke({'produto': 'Um copo inquebrável'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anúncio:\\n\\nChega de se preocupar com copos quebrados! Apresentamos o DurávelGlass, o copo inquebrável perfeito para sua casa, restaurante, festa ou aventura ao ar livre.\\n\\nFeito com material resistente e durável, o DurávelGlass é a opção ideal para quem busca praticidade e segurança. Com ele, você não precisa mais se preocupar com quedas, batidas ou crianças agitadas em casa.\\n\\nSeja para servir bebidas em uma festa animada, para levar em uma trilha ou acampamento, ou simplesmente para uso diário em casa, o DurávelGlass é o companheiro perfeito para todas as ocasiões.\\n\\nNão perca mais tempo quebrando copos frágeis e invista em durabilidade com o DurávelGlass. Garanta já o seu e tenha a tranquilidade de um copo que não quebra!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = parallel | prompt | ChatOpenAI() | StrOutputParser()\n",
    "chain.invoke({'produto': 'Um copo inquebrável'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, Maria!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def cumprimentar(nome):\n",
    "    return f'Olá, {nome}!'\n",
    "\n",
    "runnable_cumprimentar = RunnableLambda(cumprimentar)\n",
    "\n",
    "resultado = runnable_cumprimentar.invoke('Maria')\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Dado o produto com o seguinte nome e seguinte\n",
    "público potencial, desenvolva um anúncio para o produto.\n",
    "                                          \n",
    "Nome do produto: {nome_produto}\n",
    "Característica do produto: {produto}\n",
    "Público: {publico}\"\"\")\n",
    "\n",
    "parallel = RunnablePassthrough().assign(**{'nome_produto': chain_nome, 'publico': chain_clientes})\n",
    "chain = parallel | prompt | ChatOpenAI() | StrOutputParser()\n",
    "chain.invoke({'produto': 'Copo inquebrável'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
